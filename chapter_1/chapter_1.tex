\documentclass[a4paper]{book}
\special{dvipdfmx:config z 0} %取消PDF压缩，加快速度，最终版本生成的时候最好把这句话注释掉

\usepackage{amssymb}
\usepackage{geometry}
\geometry{
	left=2cm,
	right=2cm,
	top=2cm,
	bottom=2cm,
}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,            %链接颜色
    linkcolor=blue,             %内部链接
    filecolor=magenta,          %本地文档
    urlcolor=cyan,              %网址链接
}
\usepackage[none]{hyphenat}		% 阻止长单词分在两行
\usepackage{mathrsfs}
\usepackage[version=4]{mhchem}
\usepackage{subcaption}
\usepackage{titlesec}

\RequirePackage[many]{tcolorbox}
\tcbset{
    boxed title style={colback=magenta},
	breakable,
	enhanced,
	sharp corners,
	attach boxed title to top left={yshift=-\tcboxedtitleheight,  yshifttext=-.75\baselineskip},
	boxed title style={boxsep=1pt,sharp corners},
    fonttitle=\bfseries\sffamily,
}

\definecolor{skyblue}{rgb}{0.54, 0.81, 0.94}

\newcounter{exercise}[chapter]
\newcounter{solution}[chapter]
\newcounter{eqs}[solution]

\newenvironment{sequation}
  {\begin{equation}\stepcounter{eqs}\tag{\thesolution-\theeqs}}
  {\end{equation}}

\newtcolorbox[use counter=exercise, number within=chapter, number format=\arabic]{exercise}[1][]{
    title={Exercise~\thetcbcounter},
    colframe=skyblue,
    colback=skyblue!12!white,
    boxed title style={colback=skyblue},
    overlay unbroken and first={
        \node[below right,font=\small,color=skyblue,text width=.8\linewidth]
        at (title.north east) {#1};
    }
}

\newtcolorbox[use counter=solution, number within=chapter, number format=\arabic]{solution}[1][]{
    title={Solution~\thetcbcounter},
    colframe=teal!60!green,
    colback=green!12!white,
    boxed title style={colback=teal!60!green},
    overlay unbroken and first={
        \node[below right,font=\small,color=red,text width=.8\linewidth]
        at (title.north east) {#1};
    }
}

% special new commands for common symbols used in the article
\newcommand\tr[1]{\mathrm{tr(#1)}}
\newcommand*{\dif}{\mathop{}\!\mathrm{d}}
\renewcommand\det[1]{\mathrm{det\left(#1\right)}}

\newcommand{\A}{{\bf A}}
\newcommand{\B}{{\bf B}}
\newcommand{\C}{{\bf C}}
\newcommand{\I}{{\bf 1}}
\newcommand{\U}{{\bf U}}
\newcommand{\Op}{{\bf O}}

\titleformat{\chapter}[display]
  {\bfseries\Large}
  {\filright\MakeUppercase{\chaptertitlename} \Huge\thechapter}
  {1ex}
  {\titlerule\vspace{1ex}\filleft}
  [\vspace{1ex}\titlerule]
  
\allowdisplaybreaks

\begin{document}

	\chapter{Mathematical Review}
	
	\section{Linear Algebra}
	
	\subsection{Three-Dimensional Vector Algebra}
	
	% 1.1
	\begin{exercise}
	a) Show that $O_{ij} = \hat e_i \cdot \mathscr{O} \hat{e}_j$. b) If $\mathscr{O} \vec{a} = \vec{b}$ show that $b_i = \displaystyle \sum_j O_{ij} a_j$.
	\end{exercise}
	
	\begin{solution}
	
	\begin{enumerate}
	
	\item Using (1.7) and (1.13), we get that
	\begin{sequation}
		\hat{e}_i \cdot \mathscr{O} \hat{e}_j = \hat{e}_i \cdot \sum_{k=1}^3 \hat{e}_k O_{kj} = \sum_{k=1}^3 \hat{e}_i \cdot  \hat{e}_k O_{kj} = \sum_{k=1}^3 \delta_{ik} O_{kj} = O_{ij}.
	\end{sequation}
	
	\item Similarly,
	\[
		\vec{b} = \sum_{i=1}^3 b_i\hat{e}_i = \mathscr{O} \vec{a} = \mathscr{O} \sum_{j=1}^3 a_j \hat{e}_j = \sum_{j=1}^3 a_j \mathscr{O} \hat{e}_j = \sum_{j=1}^3 a_j \sum_{i=1}^3 \hat{e}_i O_{ij} = \sum_{i=1}^3 \Big( \sum_{j=1}^3 O_{ij} a_j \Big) \hat{e}_i.
	\]
	From the uniqueness of linear expression by a basis, we arrive at
	\begin{sequation}
		b_i = \sum_{j=1}^3 O_{ij} a_j.
	\end{sequation}
	% These two conclusions have been proved.
	
	\end{enumerate}
	
	\end{solution}

	% 1.2
	\begin{exercise}
	Calculate $[\A,\B]$ and $\{\A,\B\}$ when
	\[
		\A = \begin{pmatrix}
					1 & 1 & 0 \\
					1 & 2 & 2 \\
					0 & 2 & -1
		\end{pmatrix}, \quad \B = \begin{pmatrix}
					1 & -1 & 1 \\
					-1 & 0 & 0 \\
					1 & 0 & 1
		\end{pmatrix}.
	\]
	\end{exercise}

	\begin{solution}
	
	\begin{align*}
		[\A,\B] &\equiv \A\B-\B\A = \begin{pmatrix}
		0 & -1 & 1 \\
		1 & -1 & 3 \\
		-3 & 0 & -1
		\end{pmatrix} - \begin{pmatrix}
		0 & 1 & -3 \\
		-1 & -1 & 0 \\
		1 & 3 & -1
		\end{pmatrix} = \begin{pmatrix}
					0 & -2 & 4 \\
					2 & 0 & 3 \\
					-4 & -3 & 0
		\end{pmatrix}, \\
		\{\A,\B\} &\equiv \A\B + \B\A = \begin{pmatrix}
		0 & -1 & 1 \\
		1 & -1 & 3 \\
		-3 & 0 & -1
		\end{pmatrix} + \begin{pmatrix}
		0 & 1 & -3 \\
		-1 & -1 & 0 \\
		1 & 3 & -1
		\end{pmatrix} = 
		\begin{pmatrix}
					0	&	0	&	-2	\\
					0	&	-2	&	3	\\
					-2	&	3	&	-2
		\end{pmatrix}.
	\end{align*}
	
	\end{solution}
	
	\subsection{Matrices}
	
	% 1.3
	\begin{exercise}
		If $\A$ is an $N \times M$ matrix and $\B$ is a $M \times K$ matrix show that $(\A\B)^\dagger = \B^\dagger \A^\dagger$.
	\end{exercise}
	
	\begin{solution}
	
	It is obvious that
	\begin{sequation}
		(\B^\dagger \A^\dagger)_{ij} = \sum_{k=1}^M (\B^\dagger)_{ik} (\A^\dagger)_{kj} = \sum_{k=1}^M B_{ki}^* A^*_{jk} = \left(\sum_{k=1}^M A_{jk} B_{ki} \right)^* = [(\A\B)^*]_{ji} = [(\A\B)^\dagger]_{ij} ,
	\end{sequation}
	which means that $(\A\B)^\dagger = \B^\dagger \A^\dagger$.
	
	\end{solution}
	
	% 1.4
	\begin{exercise}
	Show that 
	\begin{enumerate}
	
	\item[a.] $\tr{\A\B} = \tr{\B\A}$.
	
	\item[b.] $(\A\B)^{-1}=\B^{-1}\A^{-1}$.
	
	\item[c.] If $\U$ is unitary and $\B = \U^\dagger \A \U$, then $\A = \U \B \U^\dagger$.
	
	\item[d.] If the product $\C=\A\B$ of two Hermitian matrices is also Hermitian, then $\A$ and $\B$ commute.
	
	\item[e.] If $\A$ is Hermitian then $\A^{-1}$, if it exists, is also Hermitian.
	
	\item[f.] If $\A=\begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22}	\end{pmatrix}$, then $\A^{-1}=\frac{1}{ ( A_{11} A_{22} - A_{12} A_{21} ) }\begin{pmatrix} A_{22} & -A_{12} \\ -A_{21} & A_{11}	\end{pmatrix}$.
	
	\end{enumerate}
	\end{exercise}
	
	\begin{solution}
	\begin{enumerate}
	
	\item[a.] At this time, we assume that $\A$ is an $N \times M$ matrix while $\B$ is a $M \times N$ matrix. Then,
	\begin{sequation}
		\tr{\A\B} = \sum_{i=1}^N (\A\B)_{ii} = \sum_{i=1}^N \sum_{k=1}^M A_{ik} B_{ki} = \sum_{k=1}^M \sum_{i=1}^N B_{ki} A_{ik} = \sum_{k=1}^M (\B\A)_{kk} = \tr{\B\A}.
	\end{sequation}
	
	From this issue, we assume that both $\A$ and $\B$ are $N \times N$ matrices.
	
	\item[b.] We find that
	\[
		\A\B (\B^{-1}\A^{-1}) = \A(\B \B^{-1})\A^{-1} = \A \A^{-1} = \I.
	\]
	Since the inverse of a matrix is unique, we immediately get that
	\begin{sequation}
		(\A\B)^{-1}=\B^{-1}\A^{-1}.
	\end{sequation}
	
	\item[c.] Due to $\B = \U^\dagger \A \U$, we can find
	\begin{sequation}
		\A = \I \A \I = (\U \U^\dagger) \A (\U \U^\dagger) = \U (\U^\dagger \A \U )\U^\dagger = \U \B \U^\dagger.
	\end{sequation}
	
	\item[d.] Because $\C=\A\B$ of two Hermitian matrices is also Hermitian, we know that
	\[
		\C^\dagger = (\A\B)^\dagger = \B^\dagger \A^\dagger = \C = \A \B. 
	\]
	With $\A^\dagger = \A, \, \B^\dagger = \B$, we find
	\begin{sequation}
		\B^\dagger \A^\dagger = \B \A = \A \B.
	\end{sequation}
	In other words, $\A$ and $\B$ commute.
	
	\item[e.] It is obvious that if $\A^{-1}$ exists,
	\[
		(\A^{-1})^\dagger \A^\dagger = (\A \A^{-1})^\dagger = \I^\dagger = \I.
	\]
	We know $(\A^\dagger)^{-1} = (\A^{-1})^\dagger$. Then, with $\A = \A^\dagger$, we find that
	\begin{sequation}
		(\A^{-1})^\dagger = (\A^\dagger)^{-1} = \A^{-1}.
	\end{sequation}
	Namely, $\A^{-1}$ is also Hermitian if it exists.
	
	\item[f.] If $A_{11}A_{22}-A_{12}A_{21}\neq 0$, we can find
	\[
		\A \times \frac{1}{A_{11}A_{22}-A_{12}A_{21}}\begin{pmatrix} A_{22} & -A_{12} \\ -A_{21} & A_{11}	\end{pmatrix} = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix},
	\]
	which means that if $A_{11}A_{22}-A_{12}A_{21} \neq 0$,
	\begin{sequation}
		\A^{-1} = \frac{1}{ A_{11} A_{22} - A_{12} A_{21} }\begin{pmatrix} A_{22} & -A_{12} \\ -A_{21} & A_{11}	\end{pmatrix}.
	\end{sequation}
		
	\end{enumerate}
	
	\end{solution}
	
	\subsection{Determinants}
	
	% 1.5
	\begin{exercise}
	Verify the above properties for $2\times2$ determinants.
	\end{exercise}
	
	\begin{solution}

	From (1.39), we can verify the above properties for $2\times2$ determinants.

	\begin{itemize}
	
	\item[1.] If each element in the first row of $|\A|$ is zero, we will find that
	\[
		\begin{vmatrix}
			0  & 0 \\ A_{21} &  A_{22} 
		\end{vmatrix} = 0 \times A_{22} - 0 \times A_{21} = 0 .
	\]
	In the same way, we can verify that if each element in a row or in a column is zero, the value of the $2 \times 2$ determinant $|\A|$ is zero.
	
	\item[2.] If $(\A)_{ij} = A_{ii} \delta_{ij}$, we will find that
	\[
		\begin{vmatrix}
			A_{11}  & 0 \\ 0 & A_{22} 
		\end{vmatrix} = A_{11} A_{22} - 0 \times 0 = A_{11} A_{22} = \prod_{ i=1 }^2 A_{ii} .
	\]
	
	\item[3.] We can interchange two rows of the $2\times2$ determinant $|\A|$ and find that
	\[
		\begin{vmatrix}
			A_{21}  & A_{22} \\ A_{11} & A_{12} 
		\end{vmatrix} = A_{21} A_{12} - A_{11} A_{22} = - ( A_{11} A_{22} - A_{12} A_{21} ) = - \begin{vmatrix}
			A_{11}  & A_{12} \\ A_{21} & A_{22} 
		\end{vmatrix} .
	\]
	In the same way, we can verify that a single interchange of any two rows (or columns) of a determinant changes its sign.
	
	\item[4.] Note that $(\A^\dagger)_{ij} = A^*_{ji}$,
	\[
		(| \A^\dagger |)^* = \begin{vmatrix}
			A^*_{11}  & A^*_{21} \\ A^*_{12} & A^*_{22} 
		\end{vmatrix}^* = ( A^*_{11} A^*_{22} - A^*_{12} A^*_{21} )^* = A_{11} A_{22} - A_{12} A_{21} = | \A | .
	\]	
	
	\item[5.] It is evident that for two $2\times2$ matrices $\A$ and $\B$, the determinant of their product is
	\[
		\A \B = \begin{pmatrix}
			A_{11} & A_{12} \\ A_{21} & A_{22} 
		\end{pmatrix} \begin{pmatrix}
			B_{11} & B_{12} \\ B_{21} & B_{22} 
		\end{pmatrix} = \begin{pmatrix}
			A_{11} B_{11} + A_{12} B_{21} & A_{11} B_{12} + A_{12} B_{22} \\
			A_{21} B_{11} + A_{22} B_{21} & A_{21} B_{12} + A_{22} B_{22}
		\end{pmatrix} .
	\]
	Thus, we can find that
	\begin{align*}
		\det{\A \B} &= \begin{vmatrix}
			A_{11} B_{11} + A_{12} B_{21} & A_{11} B_{12} + A_{12} B_{22} \\
			A_{21} B_{11} + A_{22} B_{21} & A_{21} B_{12} + A_{22} B_{22}
		\end{vmatrix} \\
		&= ( A_{11} B_{11} + A_{12} B_{21} ) ( A_{21} B_{12} + A_{22} B_{22} ) - ( A_{11} B_{12} + A_{12} B_{22} ) ( A_{21} B_{11} + A_{22} B_{21} ) \\
		&= A_{11} A_{21} B_{11} B_{12} + A_{11} A_{22} B_{11} B_{22} + A_{12} A_{21} B_{12} B_{21} + A_{12} A_{22} B_{21} B_{22} \\
		&\hspace{4em} - A_{11} A_{21} B_{11} B_{12} - A_{11} A_{22} B_{12} B_{21} - A_{12} A_{21} B_{11} B_{22} - A_{12} A_{22} B_{21} B_{22} \\
		&= A_{11} A_{22} ( B_{11} B_{22} - B_{12} B_{21} ) + A_{12} A_{21} ( B_{12} B_{21} - B_{11} B_{22} ) \\
		&= ( A_{11} A_{22} - A_{12} A_{21} ) ( B_{11} B_{22} - B_{12} B_{21} ) = | \A | | \B | .
	\end{align*}
	
	\end{itemize}		
	
	\end{solution}
	
	% 1.6
	\begin{exercise}
	Using properties (1)-(5) prove that in general
	\begin{itemize}
	
	\item[6.] If any two rows (or columns) of a determinant are equal, the value of the determinant is zero.
	
	\item[7.] $|\A^{-1}| = (|\A|)^{-1}$.
	
	\item[8.] If $\A\A^\dagger=\I$, then $|\A|(|\A|)^*=1$.
	
	\item[9.] If $\U^\dagger\Op\U = {\bf \Omega}$ and $\U^\dagger\U=\U\U^\dagger=\I$, then $|\Op|=|{\bf \Omega}|$.	
	
	\end{itemize}
	\end{exercise}
	
	\begin{solution}
	
	\begin{itemize}
	
	\item[6.] According to the property 3, a single interchange of any two rows (or columns) of a determinant $|\A|$ generates a minus sign. However, a single interchange of any two equal rows (or columns) does not change $|\A|$, which means $|\A| = -|\A|$ and thus $|\A| = 0$.
	
	\item[7.] For a general square matrix $\A$, it is evident that
	\[
		1 = |\I| = |\A \A^{-1}| = |\A| |\A^{-1}| .
	\] 
	Therefore,
	\[
		| \A^{-1} | = ( |\A| )^{-1} .
	\]
	
	\item[8.] Using the property 4, we find that
	\[
		1 = |\I| = | \A \A^\dagger | = | \A | | \A^\dagger | = | \A | (| \A |)^* .
	\]
	
	\item[9.] Note that	
	\[
		\U \U^\dagger = \I \Leftrightarrow \U^{-1} = \U^\dagger \Rightarrow | \U^{-1} | = | \U^\dagger | = | \U |^* ,
	\]	
	and thus $1 = | \I | = | \U^\dagger \U | = | \U^\dagger | | \U | = | \U |^* | \U |$. Therefore, we obtain that
	\[
		| {\bf \Omega} | = | \U^\dagger \Op \U | = | \U^\dagger | | \Op \U | = | \U |^* | \Op | | \U | = | \Op | | \U |^* | \U | = | \Op | .
	\]
	
	\end{itemize}		
	
	\end{solution}
	
	% 1.7
	\begin{exercise}
	Using Eq.(1.39), note that the inverse of a $2\times2$ matrix $\A$ obtained in Exercise 1.4f can be written as
	\[
		\A^{-1} = \frac{1}{|\A|}\begin{pmatrix}
			A_{22} & -A_{12} \\ -A_{21} & A_{11}
		\end{pmatrix}
	\]
	and thus $\A^{-1}$ does not exist when $|\A|=0$. This result holds in general for $N\times N$ matrices. Show that the equation
	\[
		\A {\bf c} = {\bf 0}
	\]
	where $\A$ is an $N \times N$ matrix and ${\bf c}$ is a column matrix with elements $c_i$, $i=1,2,\ldots,N$ can have a nontrivial solution (${\bf c} \neq 0$) only when $|\A|=0$.
	\end{exercise}
	
	\begin{solution}
	
	This conclusion is a corollary of Cramer's rule, whose WIKIPEDIA's url is \url{https://en.wikipedia.org/wiki/Cramer's_rule}. Its proof is too lengthy to be omitted here.
	
	\end{solution}
	
	\subsection{\texorpdfstring{$N$}--Dimentional Complex Vector Spaces}
	
	\subsection{Change of Basis}
	
	% 1.8
	\begin{exercise}
	Show that the trace of a matrix is invariant under a unitary transformation, i.e., if ${\bf \Omega} = \U^\dagger \Op \U$ then show that $\tr{{\bf \Omega}}=\tr{\Op}$.
	\end{exercise}
	
	\begin{solution}
	
	Using the conclusion of Exercise 1.4(a), we find that
	\begin{sequation}
		\tr{{\bf \Omega}} = \tr{ \U^\dagger \Op \U } = \tr{ \Op \U \U^\dagger } = \tr{ \Op \I } = \tr{ \Op } .
	\end{sequation}		
	
	\end{solution}
	
	\subsection{The Eigenvalue Problem}
	
	% 1.9
	\begin{exercise}
	Show that Eq.(1.90) contains Eq.(1.87) for all $\alpha=1,2,\ldots,N$.
	\end{exercise}
	
	\begin{solution}
	
	It is evident that
	\begin{sequation}
		\Op \U = \Op ( {\bf c}^1 , {\bf c}^2 , \cdots , {\bf c}^N ) = ( \Op {\bf c}^1 , \Op {\bf c}^2 , \cdots , \Op {\bf c}^N ) = ( \omega_1 {\bf c}^1 , \omega_2 {\bf c}^2 , \cdots , \omega_N {\bf c}^N ) = \U {\bf \omega} ,
	\end{sequation}
	which equals (1.87) for all $\alpha=1,2,\ldots,N$.
	
	\end{solution}
	
	% 1.10
	\begin{exercise}
	Since the components of an eigenvector can be found from the eigenvalue equation only to within a multiplicative constant, which is later determined by the normalization, one can set $c_1 = 1$ and $c_2 = c$ in Eq.(1.94). If this is done, Eq.(1.94) becomes
	\begin{align*}
		O_{11} + O_{12} c &= \omega \\
		O_{21} + O_{22} c &= \omega c. 
	\end{align*}
	After eliminating $c$, find the two roots of the resulting equation and show that they are the same as those given in Eq.(1.96). This technique, which we shall use numerous times in the book for finding the lowest eigenvalue of a matrix, is basically the secular determinant approach {\it without} determinants. Thus one can use it to find the lowest eigenvalue of certain $N \times N$ matrices without having to evaluate an $N \times N$ determinant.
	\end{exercise}
	
	\begin{solution}
	
	The proof should be discussed according to the value of $O_{12} = O_{21}$.
	
	\begin{itemize}
	
	\item When $O_{12} = O_{21} = 0$, assume that $c\neq 0$ and we find that
	\[
		\omega_1 = O_{11} , \quad \omega_2 = O_{22} .
	\]
	If $c=0$, we find that
	\[
		\begin{pmatrix}
			O_{11} & 0 \\ 0 & O_{22} 
		\end{pmatrix} \begin{pmatrix}
			1 \\ 0 
		\end{pmatrix} = \begin{pmatrix}
			Q_{11} \\ 0
		\end{pmatrix} = Q_{11} \begin{pmatrix}
			1 \\ 0
		\end{pmatrix} .
	\]
	At this time, the only $\omega = O_{11}$.
	
	\item When $O_{12} = O_{21} \neq 0$, from the first equation, we get that
	\[
		c = \frac{ \omega - O_{11} }{ O_{12} } .
	\]
	Substitute it into the second equation, we obtain that
	\[
		O_{21} = ( \omega - O_{22} ) c = ( \omega - O_{22} ) \frac{ \omega - O_{11} }{ O_{12} },
	\]
	which equals
	\[
		( \omega - O_{11} )( \omega - O_{22} ) - O_{12} O_{21} = \omega^2 - ( O_{11} + O_{22} ) \omega + ( O_{11} O_{22} - O_{12} O_{21} ) = 0 .
	\]	
	The discriminant of the quadratic equation is
	\[
		\Delta_\omega = ( O_{11} + O_{22} )^2 - 4 \times 1 \times ( O_{11} O_{22} - O_{12} O_{21} ) = ( O_{11} - O_{22} )^2 + 4 O_{12} O_{21} > 0 ,
	\]
	and the two roots are
	\[
		\omega_\pm = \frac{1}{2} \left[ O_{11} + O_{22} \pm \sqrt{ ( O_{11} - O_{22} )^2 + 4 O_{12} O_{21} } \right] .
	\]
	\end{itemize}
	
	Note that
	\begin{align*}
		\lim_{O_{12} \rightarrow 0} \omega_\pm &= \lim_{O_{12} \rightarrow 0} \frac{1}{2} \left[ O_{11} + O_{22} \pm \sqrt{ ( O_{11} - O_{22} )^2 + 4 O_{12} O_{21} } \right] \\
		&= \frac{1}{2} \left( O_{11} + O_{22} \right) \pm \frac{1}{2} \lim_{O_{12} \rightarrow 0} \sqrt{ ( O_{11} - O_{22} )^2 + 4 O_{12} O_{21} } \\
		&= \frac{1}{2} \left( O_{11} + O_{22} \right) \pm \frac{1}{2} | O_{11} - O_{22} | .
	\end{align*}
	
	When $O_{11} \ge O_{22}$,
	\[
		\omega_+ = \frac{1}{2} \left( O_{11} + O_{22} \right) + \frac{1}{2} \left( O_{11} - O_{22} \right) = O_{11} , \quad \omega_- = \frac{1}{2} \left( O_{11} + O_{22} \right) - \frac{1}{2} \left( O_{11} - O_{22} \right) = O_{22} .
	\]	
	while $O_{11} < O_{22}$,
	\[
		\omega_+ = \frac{1}{2} \left( O_{11} + O_{22} \right) + \frac{1}{2} \left( O_{22} - O_{11} \right) = O_{22} , \quad \omega_- = \frac{1}{2} \left( O_{11} + O_{22} \right) - \frac{1}{2} \left( O_{22} - O_{11} \right) = O_{11} .
	\]	
	
	In conclusion, we obtain that
	\[
		\lim_{O_{12} \rightarrow 0} \omega_1 = O_{11} , \quad \lim_{O_{12} \rightarrow 0} \omega_2 = O_{22} .
	\]
	Thus, the special case of $O_{12} = O_{21} = 0$ can be merged in the general case. And we conclude that two roots obtained by eliminating $c$ are the same as those given in Eq.(1.96).
	
	\end{solution}
	
	% 1.11
	\begin{exercise}
	Consider the matrices
	\begin{equation*}
		\A = \begin{pmatrix} 3 & 1 \\ 1 & 3 \end{pmatrix}, \,  \B = \begin{pmatrix} 3 & 1 \\ 1 & 2 \end{pmatrix}.
	\end{equation*}
	Find numerical values for the eigenvalues and corresponding eigenvectors of these matrices by a) the secular determinant approach; b) the unitary transformation approach. You will see that approach (b) is much easier.
	\end{exercise}
	
	\begin{solution}
	
	Using the secular determinant approach,
	\begin{align*}
		| \A - \omega \I | = \begin{vmatrix}
			3 - \omega & 1 \\ 1 & 3 - \omega 
		\end{vmatrix} = ( 3 - \omega )^2 - 1 = ( 4 - \omega ) ( 2 - \omega ) = 0.
	\end{align*}
	
	\[
		\omega_1 = 2 , \quad \omega_2 = 4.
	\]
	
	\[
		\A - \omega_1 \I = \begin{pmatrix}
			3 - 2 & 1 \\ 1 & 3 - 2
		\end{pmatrix} = \begin{pmatrix}
			1 & 1 \\ 1 & 1
		\end{pmatrix} \Rightarrow \begin{pmatrix}
			1 & 1 \\ 0 & 0
		\end{pmatrix}
	\]
	The eigenvector is $(1,-1)^T$.
	
		\[
		\A - \omega_2 \I = \begin{pmatrix}
			3 - 4 & 1 \\ 1 & 3 - 4
		\end{pmatrix} = \begin{pmatrix}
			-1 & 1 \\ 1 & -1
		\end{pmatrix} \Rightarrow \begin{pmatrix}
			1 & -1 \\ 0 & 0
		\end{pmatrix}
	\]
	The eigenvector is $(1,1)^T$.
	\end{solution}

	\subsection{Functions of Matrices}
	
\end{document}